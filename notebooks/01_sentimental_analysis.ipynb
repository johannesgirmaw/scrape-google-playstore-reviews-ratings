{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cfeb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax # For converting logits to probabilities\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b89a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "# Define the directory where cleaned data is stored\n",
    "CLEANED_DATA_DIR = \"../data/cleaned\"\n",
    "# Define the directory where sentiment analysis results will be saved\n",
    "SENTIMENT_RESULTS_DIR = \"../data/sentiment_analysis\"\n",
    "\n",
    "# Hugging Face model for sentiment analysis\n",
    "SENTIMENT_MODEL_NAME = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Ensure the output directory for sentiment results exists\n",
    "if not os.path.exists(SENTIMENT_RESULTS_DIR):\n",
    "    os.makedirs(SENTIMENT_RESULTS_DIR)\n",
    "    print(f\"Created sentiment results directory: {SENTIMENT_RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9947e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentiment model: distilbert-base-uncased-finetuned-sst-2-english...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1f8af4cea64e1f8adff98be31975b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936d1b49dcb148ad9646e889d1d6f644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a22cabde28403f8e8f6cb8c387a58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301ad937d1af4824a7108887aeffbd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and moved to cpu.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Model and Tokenizer ---\n",
    "print(f\"Loading sentiment model: {SENTIMENT_MODEL_NAME}...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(SENTIMENT_MODEL_NAME)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        SENTIMENT_MODEL_NAME)\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(f\"Model loaded successfully and moved to {device}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or tokenizer: {e}\")\n",
    "    print(\"Please ensure you have an active internet connection and `transformers` library is installed.\")\n",
    "    # Exit or handle gracefully if model cannot be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d588f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data Loading Function ---\n",
    "def load_cleaned_data(directory):\n",
    "    \"\"\"\n",
    "    Loads all cleaned CSV files from the specified directory into a list of DataFrames.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing cleaned CSV files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are bank names (derived from filenames)\n",
    "              and values are pandas DataFrames containing the cleaned reviews.\n",
    "    \"\"\"\n",
    "    all_files = glob.glob(os.path.join(directory, \"*_cleaned.csv\"))\n",
    "    if not all_files:\n",
    "        print(\n",
    "            f\"No cleaned CSV files found in {directory}. Please ensure Task 1 was run correctly.\")\n",
    "        return {}\n",
    "\n",
    "    bank_data = {}\n",
    "    for filepath in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            # Extract bank name from filename\n",
    "            # Example: \"Commercial_Bank_of_Ethiopia_mobile_banking_reviews_cleaned.csv\"\n",
    "            # -> \"Commercial Bank of Ethiopia\"\n",
    "            filename = os.path.basename(filepath)\n",
    "            bank_name = filename.replace(\n",
    "                \"_mobile_banking_reviews_cleaned.csv\", \"\").replace(\"_\", \" \")\n",
    "            bank_data[bank_name] = df\n",
    "            print(\n",
    "                f\"Loaded {len(df)} reviews for '{bank_name}' from {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {e}\")\n",
    "    return bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b69be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4. Sentiment Analysis Function ---\n",
    "def analyze_sentiment(texts, tokenizer, model, device, batch_size=32):\n",
    "    \"\"\"\n",
    "    Computes sentiment scores and labels for a list of texts using the pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        texts (list): A list of review texts.\n",
    "        tokenizer: Loaded Hugging Face tokenizer.\n",
    "        model: Loaded Hugging Face sentiment model.\n",
    "        device (torch.device): Device to run the model on (cpu or cuda).\n",
    "        batch_size (int): Number of texts to process in each batch.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - list: List of sentiment labels ('positive', 'negative').\n",
    "            - list: List of sentiment scores (probability of the predicted label).\n",
    "    \"\"\"\n",
    "    if not texts:\n",
    "        return [], []\n",
    "\n",
    "    sentiment_labels = []\n",
    "    sentiment_scores = []\n",
    "\n",
    "    # Process texts in batches to improve efficiency\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        # Tokenize and move to device\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=model.config.max_position_embeddings,  # Use model's max length\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Logits are the raw outputs from the model before activation (like softmax)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        # Apply softmax to convert logits to probabilities\n",
    "        # Move back to CPU for numpy operation\n",
    "        probabilities = softmax(logits.cpu().numpy(), axis=1)\n",
    "\n",
    "        # The SST-2 model usually outputs 2 classes: 0 for negative, 1 for positive.\n",
    "        # We can verify this from model.config.id2label if needed.\n",
    "        # model.config.id2label will typically be {0: 'LABEL_0', 1: 'LABEL_1'}\n",
    "        # and from documentation, LABEL_0 is negative, LABEL_1 is positive.\n",
    "\n",
    "        for j in range(len(batch_texts)):\n",
    "            # Get the index of the highest probability\n",
    "            predicted_class_id = np.argmax(probabilities[j])\n",
    "            # Score for the predicted label\n",
    "            score = probabilities[j, predicted_class_id]\n",
    "\n",
    "            # Map the predicted class ID to sentiment label\n",
    "            # Based on standard SST-2 fine-tuning: 0 -> negative, 1 -> positive\n",
    "            if predicted_class_id == 0:\n",
    "                label = 'negative'\n",
    "            else:  # predicted_class_id == 1\n",
    "                label = 'positive'\n",
    "\n",
    "            sentiment_labels.append(label)\n",
    "            # Ensure float for CSV saving\n",
    "            sentiment_scores.append(float(score))\n",
    "\n",
    "    print(f\"Analyzed sentiment for {len(texts)} reviews.\")\n",
    "    return sentiment_labels, sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f6a7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Aggregation Function ---\n",
    "def aggregate_sentiment(df):\n",
    "    \"\"\"\n",
    "    Aggregates sentiment by bank and rating, computing mean sentiment scores.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'bank', 'rating', and 'sentiment_score' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with aggregated sentiment results.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Aggregating sentiment data ---\")\n",
    "\n",
    "    # Convert sentiment_label to a numerical value for mean calculation\n",
    "    # For simplicity, assign -1 for negative, 1 for positive. Neutral can be 0 if we implement it.\n",
    "    df['numerical_sentiment'] = df['sentiment_label'].apply(\n",
    "        # 0 for neutral if present\n",
    "        lambda x: 1 if x == 'positive' else (-1 if x == 'negative' else 0)\n",
    "    )\n",
    "\n",
    "    # Aggregate by bank and rating\n",
    "    # We'll calculate the mean of 'numerical_sentiment'\n",
    "    # and also count reviews for context\n",
    "    aggregated_df = df.groupby(['bank', 'rating']).agg(\n",
    "        mean_sentiment=('numerical_sentiment', 'mean'),\n",
    "        num_reviews=('review', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    print(\"Sentiment aggregation complete.\")\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e9c93de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sentiment analysis pipeline...\n",
      "Loaded 400 reviews for 'Commercial Bank of Ethiopia Mobile' from Commercial_Bank_of_Ethiopia_Mobile_mobile_banking_reviews_cleaned.csv\n",
      "Loaded 400 reviews for 'Dashen Bank Mobile' from Dashen_Bank_Mobile_mobile_banking_reviews_cleaned.csv\n",
      "Loaded 400 reviews for 'Bank of Abyssinia Mobile' from Bank_of_Abyssinia_Mobile_mobile_banking_reviews_cleaned.csv\n",
      "\n",
      "Processing sentiment for Commercial Bank of Ethiopia Mobile...\n",
      "Analyzed sentiment for 400 reviews.\n",
      "Added sentiment to Commercial Bank of Ethiopia Mobile's DataFrame.\n",
      "\n",
      "--- Aggregating sentiment data ---\n",
      "Sentiment aggregation complete.\n",
      "Successfully saved reviews with sentiment for Commercial Bank of Ethiopia Mobile to: ../data/sentiment_analysis/Commercial_Bank_of_Ethiopia_Mobile_reviews_with_sentiment.csv\n",
      "\n",
      "Processing sentiment for Dashen Bank Mobile...\n",
      "Analyzed sentiment for 400 reviews.\n",
      "Added sentiment to Dashen Bank Mobile's DataFrame.\n",
      "\n",
      "--- Aggregating sentiment data ---\n",
      "Sentiment aggregation complete.\n",
      "Successfully saved reviews with sentiment for Dashen Bank Mobile to: ../data/sentiment_analysis/Dashen_Bank_Mobile_reviews_with_sentiment.csv\n",
      "\n",
      "Processing sentiment for Bank of Abyssinia Mobile...\n",
      "Analyzed sentiment for 400 reviews.\n",
      "Added sentiment to Bank of Abyssinia Mobile's DataFrame.\n",
      "\n",
      "--- Aggregating sentiment data ---\n",
      "Sentiment aggregation complete.\n",
      "Successfully saved reviews with sentiment for Bank of Abyssinia Mobile to: ../data/sentiment_analysis/Bank_of_Abyssinia_Mobile_reviews_with_sentiment.csv\n",
      "\n",
      "Successfully saved aggregated sentiment results to: ../data/sentiment_analysis/aggregated_sentiment_by_bank_and_rating.csv\n",
      "\n",
      "Sample Aggregated Sentiment Data:\n",
      "                                 bank  rating  mean_sentiment  num_reviews\n",
      "0  Commercial Bank of Ethiopia Mobile       1       -0.591837           49\n",
      "1  Commercial Bank of Ethiopia Mobile       2       -0.375000           16\n",
      "2  Commercial Bank of Ethiopia Mobile       3       -0.545455           22\n",
      "3  Commercial Bank of Ethiopia Mobile       4        0.128205           39\n",
      "4  Commercial Bank of Ethiopia Mobile       5        0.678832          274\n",
      "\n",
      "Sentiment analysis pipeline complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting sentiment analysis pipeline...\")\n",
    "\n",
    "    # Load all cleaned data\n",
    "    all_banks_data = load_cleaned_data(CLEANED_DATA_DIR)\n",
    "\n",
    "    if not all_banks_data:\n",
    "        print(\"No data to process. Exiting.\")\n",
    "    else:\n",
    "        # List to hold DataFrames after sentiment analysis for all banks\n",
    "        processed_dfs = []\n",
    "\n",
    "        # List to hold aggregated sentiment results\n",
    "        all_aggregated_sentiment_dfs = []\n",
    "\n",
    "        for bank_name, df in all_banks_data.items():\n",
    "            print(f\"\\nProcessing sentiment for {bank_name}...\")\n",
    "\n",
    "            if 'review' not in df.columns or df['review'].empty:\n",
    "                print(\n",
    "                    f\"No 'review' column or empty reviews for {bank_name}. Skipping sentiment analysis.\")\n",
    "                continue\n",
    "\n",
    "            # Convert reviews to a list for batch processing\n",
    "            reviews_text = df['review'].tolist()\n",
    "\n",
    "            # Perform sentiment analysis\n",
    "            sentiment_labels, sentiment_scores = analyze_sentiment(\n",
    "                reviews_text, tokenizer, model, device\n",
    "            )\n",
    "\n",
    "            # Add sentiment results to the DataFrame\n",
    "            df['sentiment_label'] = sentiment_labels\n",
    "            # This is the probability of the predicted label\n",
    "            df['sentiment_score'] = sentiment_scores\n",
    "\n",
    "            processed_dfs.append(df)\n",
    "            print(f\"Added sentiment to {bank_name}'s DataFrame.\")\n",
    "\n",
    "            # Aggregate sentiment for the current bank\n",
    "            if not df.empty:\n",
    "                bank_aggregated_sentiment = aggregate_sentiment(df)\n",
    "                all_aggregated_sentiment_dfs.append(bank_aggregated_sentiment)\n",
    "            else:\n",
    "                print(\n",
    "                    f\"No reviews left in DataFrame for {bank_name} after sentiment analysis, skipping aggregation.\")\n",
    "\n",
    "            # Save the DataFrame with sentiment results for the current bank\n",
    "            output_filename = f\"{bank_name.replace(' ', '_').replace('/', '_')}_reviews_with_sentiment.csv\"\n",
    "            output_filepath = os.path.join(\n",
    "                SENTIMENT_RESULTS_DIR, output_filename)\n",
    "            try:\n",
    "                df.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "                print(\n",
    "                    f\"Successfully saved reviews with sentiment for {bank_name} to: {output_filepath}\")\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"Error saving sentiment data for {bank_name} to CSV: {e}\")\n",
    "\n",
    "        # Combine all aggregated sentiment results into a single DataFrame if there's data\n",
    "        if all_aggregated_sentiment_dfs:\n",
    "            final_aggregated_df = pd.concat(\n",
    "                all_aggregated_sentiment_dfs).reset_index(drop=True)\n",
    "            aggregated_output_filename = os.path.join(\n",
    "                SENTIMENT_RESULTS_DIR, \"aggregated_sentiment_by_bank_and_rating.csv\")\n",
    "            try:\n",
    "                final_aggregated_df.to_csv(\n",
    "                    aggregated_output_filename, index=False, encoding='utf-8')\n",
    "                print(\n",
    "                    f\"\\nSuccessfully saved aggregated sentiment results to: {aggregated_output_filename}\")\n",
    "                print(\"\\nSample Aggregated Sentiment Data:\")\n",
    "                print(final_aggregated_df.head())\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving final aggregated sentiment data: {e}\")\n",
    "        else:\n",
    "            print(\"\\nNo aggregated sentiment data to save.\")\n",
    "\n",
    "    print(\"\\nSentiment analysis pipeline complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
